---
title: "Applied Machine Learning 01 Group Work"
author: "Jonas ZÃ¼rcher, Stephan Wernli, Luca Casuscelli, Dominik Vasquez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
  pdf_document:
    fig_caption: true
    number_sections: true
theme: united
---



```{r include=FALSE}
library(tidyverse)
library(e1071)  


house_data <- read_csv("../01_data/house_data.csv")
house_data$object_type_name <- as.factor(house_data$object_type_name)
house_data$num_rooms <- as.integer(house_data$num_rooms)
house_data <- house_data %>% select(object_type_name,
                                    build_year,
                                    living_area,
                                    zipcode,
                                    municipality_name,
                                    num_rooms,
                                    travel_time_private_transport,
                                    travel_time_public_transport,
                                    number_of_buildings_in_hectare,
                                    number_of_apartments_in_hectare,
                                    number_of_workplaces_in_hectare,
                                    population_in_hectare,
                                    water_percentage_1000,
                                    price)

# Log-Transform dependent variable
house_data$price.log <- log(house_data$price)
# Fix the predictors zipcode and num_rooms to be a factor
house_data$zipcode.fac <- factor(house_data$zipcode)
house_data$num_rooms.fac <- factor(house_data$num_rooms)


```

\pagebreak

## Support vector machines

The following chapter covers Support Vectore Machines. These are used to handle classification problems with a margin between separation points and their support vectors. 
In the following case, an attempt is made to classify the type of the residential object using price, number of rooms and  living area as predictors.



```{r }


house_data <- house_data %>% filter(object_type_name ==  "Einfamilienhaus"|object_type_name ==  "Wohnung")
house_data <- house_data %>% filter(living_area <= 1000)
house_data <- house_data %>% filter(num_rooms <= 20)

house_data <- house_data %>%  droplevels()
house_data$object_type_name %>%  unique()

## 75% of the sample size
smp_size <- floor(0.75 * nrow(house_data))

## set the seed to make your partition reproducible
set.seed(1)
train_ind <- sample(seq_len(nrow(house_data)), size = smp_size)
house_train <- house_data[train_ind, ]
house_test <- house_data[-train_ind, ]


ggplot(house_data, aes(x=living_area, y=price.log)) + geom_point()
ggplot(house_data, aes(x=num_rooms, y=price.log)) + geom_point()
```
After the data has been provided, it is optimized by filters. 
The aim of the optimization is to provide the SVM with a better starting point.
Now that the data for the problem is prepared, we try to apply the SVM to it.
In the first case a linear kernel will be applied.

## SVM with linear kernel


```{r }
number_of_observations <- 200
cost_range <- c(0.000005, 0.005,0.1,1,10,100,1000,10000)
svm.models <- tune(
  svm,
  object_type_name ~ price.log + living_area + num_rooms,
  data = house_train %>% top_n(number_of_observations),
  kernel = "linear",
  ranges = list(cost = cost_range),
  scale = TRUE)

svm.models <- svm.models$best.model
summary(svm.models)


plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price.log ~ living_area)
plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price.log ~ num_rooms)
table(predict = predict(svm.models, house_train),truth = house_train$object_type_name)
```

## SVM with sigmoid kernel


```{r}
number_of_observations <- 10000
cost_range <- c(0.000005, 0.005,0.1,1,10,100,1000,10000)
svm.models <- tune(
  svm,
  object_type_name ~ price.log + living_area + num_rooms,
  data = house_train %>% top_n(number_of_observations),
  kernel = "sigmoid",
  ranges = list(cost = cost_range),
  scale = TRUE)
svm.models <- svm.models$best.model
summary(svm.models)


plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price.log ~ living_area)
plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price.log ~ num_rooms)
table(predict = predict(svm.models, house_train),truth = house_train$object_type_name)
```


## SVM with radial kernel


```{r }
number_of_observations <- 200
cost_range <- c(0.000005, 0.005,0.1,1,10,100,1000,10000)
svm.models <- tune(
  svm,
  object_type_name ~ price.log + living_area + num_rooms,
  data = house_train %>% top_n(number_of_observations),
  kernel = "radial",
  ranges = list(cost = cost_range),
  scale = TRUE)
svm.models <- svm.models$best.model
summary(svm.models)


plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price.log ~ living_area)
plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price.log ~ num_rooms)
table(predict = predict(svm.models, house_train),truth = house_train$object_type_name)
```

## Conclusion 

It is not possible to differentiate clearly between an apartment and a single-family house.
Therefore, the SVM is not suitable for classification in this case.
This can be clearly seen from the fact that the data points in the graphs clearly overlap. 
The SVM can therefore not make a proper separation of the two classes.



