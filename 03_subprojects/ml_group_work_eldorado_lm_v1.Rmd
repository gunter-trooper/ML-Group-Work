---
title: "Applied Machine Learning 01 Group Work"
author: "Jonas ZÃ¼rcher, Stephan Wernli, Luca Casuscelli, Dominik Vazquez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
  html_document: default
theme: united
toc: yes
---

\pagebreak

# Load the libraries and import the dataset
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(e1071)  

house_data <- read_csv("../01_data/house_data.csv")

house_data$object_type_name <- as.factor(house_data$object_type_name)
house_data$num_rooms <- as.integer(house_data$num_rooms)


house_data <- house_data %>% select(object_type_name,
                                    build_year,
                                    living_area,
                                    zipcode,
                                    municipality_name,
                                    num_rooms,
                                    travel_time_private_transport,
                                    travel_time_public_transport,
                                    number_of_buildings_in_hectare,
                                    number_of_apartments_in_hectare,
                                    number_of_workplaces_in_hectare,
                                    population_in_hectare,
                                    water_percentage_1000,
                                    price)
```

\pagebreak

# Description of the used data set

The data set contains the following predictors: 

- object_type_name                    categorical                  
- build_year                          continues
- living_area                         continues
- zipcode                             categorical
- municipality_name                   categorical
- num_rooms                           count data/categorical
- travel_time_private_transport       continues
- travel_time_public_transport        continues 
- number_of_buildings_in_hectare      count data
- number_of_apartments_in_hectare     count data
- number_of_workplaces_in_hectare     count data
- population_in_hectare               count data
- water_percentage_1000               count data
- price                               continues

\pagebreak

# Graphical interpretation and simple linear modeling

## Graphical Interpretation
```{r}

library(ggplot2)
qplot(y = price, x = build_year,data = house_data,facets = ~ object_type_name)

ggplot(house_data, aes(x=object_type_name, y=price)) +
geom_boxplot()
```

## Linear Modeling

In this chapter we want to take a look at a simple linear regression. The linear regression is a simple but powerful tool to create a model that fits the reality pretty well in a lot of cases. Gernerally the regression coefficents are estimated from data. That means that the coefficents will be approximations in most cases. The estimation is done with the method of "Least Squares". 

In our example we want to predict the prices of real estate by fitting a linear model. In our first model where we fit all the variables we did not use the predictor municipality_name because it fully depends on the zipcode that is already part of the model.

First we have to get an idea how the data looks like. And how the obervations are distributed. That is important because a linear model assumes a normal distribution. 

```{r}
marks_at <- c(0,1000000,2000000,3000000,4000000)
marks <- c("0 Mio", "1 Mio", "2 Mio", "3 Mio", "4 Mio")
hist(house_data$price, xlim=c(0,4000000), xaxt="n", xlab='Price',main='Histogram of Price')
axis(1,at=marks_at,labels=marks)
```

As we clearly can see the data is right skewed. That means that we do not have normally distributed data. However we can try to bring the right skwewed data in a normally distributed shape by log()-transforming it. 

```{r}
hist(log(house_data$price),xlab='log(Price)',main = 'Histogram of log(Price)')
```

After log()-transforming the data (natural logarithm) we can see a nearly perfect gausian shape of the dependent variable price. So that's clearly the way to go for us here. Hence the result of the log()-transformations gives us a very usefull result. It is not necessary to use a more sophisticated approach like bootstrapping. 

Later it is of course important to back transform the predictions.

Transfromation prior to the fit:

**$Y' = ln(Y)$**

Back-Transformation after predictions of the fitted model:

**\begin{math}\hat{Y} = e^{\hat{Y'}}\end{math}**

```{r echo=TRUE, message=FALSE, warning=FALSE}
# We work for every model with a separate data set
house_data_lm <- house_data

# Log-Transform dependent variable
house_data_lm$price.log <- log(house_data_lm$price)

# Fix the predictors zipcode and num_rooms to be a factor
house_data_lm$zipcode.fac <- factor(house_data_lm$zipcode)
house_data_lm$num_rooms.fac <- factor(house_data_lm$num_rooms)

# Fit the model
lm.fit.1 <- lm(price.log ~ object_type_name + build_year + living_area 
               + zipcode.fac + num_rooms.fac + travel_time_private_transport 
               + travel_time_public_transport + number_of_buildings_in_hectare 
               + number_of_apartments_in_hectare + number_of_workplaces_in_hectare 
               + population_in_hectare, data = house_data_lm)
```

The fit of the model takes quite some time. The categorical independent variable zipcode has a lot of classes. To calculate all of the resulting parameters is a quite expensive task. 

Because the variable zipcode leads to so many parameters we restrict the output of the summary() Function. Because it would give us a parameter for every class in the variable. Anyways the interpretation of all of this parameters is not very usefull. We are more interessted at this point if the variable itself is of use or not and in the parameters related to the model itself. 

\fontsize{7}{7} \selectfont
```{r echo=FALSE}
options(width = 1500)
print(summary(lm.fit.1),max=40)
```
\fontsize{10}{10} \selectfont

The summary shows us already that the model performs pretty well. We see a multiple R-squared of 0.7 and an adjusted R-squared of about 0.67. The adjusted R-squared takes the complexity of the model into consideration. This could become usefull later when we are going to compare different models.

To check the significance of the variables we could do an Anova Test between a model with a variable and a model without that specific variable. While doing this for every variable we would find out about the variables that contribute to the model. 

There is a more convenient way. The drop1()-function does do that for us. 

\fontsize{7}{7} \selectfont
```{r echo=TRUE, message=FALSE, warning=FALSE}
drop1(lm.fit.1, test="F")
```
\fontsize{10}{10} \selectfont

The drop1()-function shows us that there are three variables that don't seem to contribute to the model in a significant way. We will now remove those variables and fit a secon modell without them. After that we will compare the two models via an Analysis Of Variance. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Fit the second model
lm.fit.2 <- lm(price.log ~ object_type_name + build_year + living_area 
               + zipcode.fac + num_rooms.fac +  number_of_apartments_in_hectare 
               + number_of_workplaces_in_hectare + population_in_hectare, 
               data = house_data_lm)

anova(lm.fit.2,lm.fit.1)
```

The anova shows that the models do not differ in explanatory power in a statistically significant way. The "Residual Sums of Squares" are practiclly the same. And the P-Value for the F-Test is relatively high. So there is strong evidence that both models perfom about the same and that we can leave out the three variables.

Let's have a look at the parameters of the less complex model.

\fontsize{7}{7} \selectfont
```{r echo=FALSE}
print(summary(lm.fit.2),max=40)
```
\fontsize{10}{10} \selectfont

Again we have restricted the output of parameters. Now we are just interessted in the R-squared values of our less complex model. 

We see that we achieve literally the same R-squared values with the less complex model. This we already expected because of the anova test we did before.

So far we didn't talk about interaction terms in our data. Let's try to find some interactions that could be interessting for our model. We will not use the categorical variables for interactions here because they would lead to a strong increase of parameters. 

First we fit a model with all the interactions we want to investigate.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Fit the second model
lm.fit.interactions <- lm(price.log ~ object_type_name + zipcode.fac + num_rooms.fac 
                          + ( build_year + living_area + travel_time_private_transport 
                              + travel_time_public_transport 
                              + number_of_buildings_in_hectare 
                              + number_of_apartments_in_hectare 
                              + number_of_workplaces_in_hectare 
                              + population_in_hectare)^2
                          , data = house_data_lm)
```
\fontsize{7}{7} \selectfont
```{r echo=FALSE}
print(summary(lm.fit.interactions),max=40)
```
\fontsize{10}{10} \selectfont

We already see that for the model that takes interactions into account the R-squared and adjusted R-sqaured are highter than before.

Now we again want to find out if we can remove some of the variables without loosing explanatory power. Therefore we use again the drop1()-function.
\fontsize{7}{7} \selectfont
```{r echo=TRUE, message=FALSE, warning=FALSE}
drop1(lm.fit.interactions, test="F")
```
\fontsize{10}{10} \selectfont

For some interactions there is strong evidence that they contribute to the model. We add all interactions that are statistically significant within the significance level of 5%. That means that we add 15 interactions to our model. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Fit the second model
lm.fit.3 <- lm(price.log ~ object_type_name + build_year + living_area 
               + zipcode.fac + num_rooms.fac +  number_of_apartments_in_hectare 
               + number_of_workplaces_in_hectare + population_in_hectare 
               + build_year:living_area + build_year:travel_time_private_transport 
               + build_year:number_of_buildings_in_hectare 
               + build_year:number_of_apartments_in_hectare 
               + build_year:number_of_workplaces_in_hectare 
               + build_year:population_in_hectare 
               + living_area:number_of_buildings_in_hectare 
               + living_area:number_of_apartments_in_hectare 
               + travel_time_private_transport:number_of_buildings_in_hectare 
               + travel_time_private_transport:number_of_apartments_in_hectare 
               + number_of_buildings_in_hectare:number_of_apartments_in_hectare 
               + number_of_buildings_in_hectare:population_in_hectare 
               + number_of_apartments_in_hectare:number_of_workplaces_in_hectare 
               + number_of_apartments_in_hectare:population_in_hectare 
               + number_of_workplaces_in_hectare:population_in_hectare
               , data = house_data_lm)
```
\fontsize{7}{7} \selectfont
```{r echo=FALSE}
print(summary(lm.fit.3),max=40)
```
\fontsize{10}{10} \selectfont

The model that contains the selected interactions matches the data slightly better than the model without the interactions. But is there a statistically significant difference between the models? We compare them by performing an Anova test.

\fontsize{7}{7} \selectfont
```{r echo=TRUE, message=FALSE, warning=FALSE}
anova(lm.fit.3,lm.fit.2)
```
\fontsize{10}{10} \selectfont

There is again strong evidence that there is a difference between the models. So we choose the model that takes the interactions into account. 

At this point we will stop to further develop the model. But with an adjusted R-squared of 0.688 we found a decent model that is able make some good predictions. 


\pagebreak

# RegressionSplines

```{r}
# library(splines)
# lm.regressionSplines <- lm(price ~ bs(living_area, df = 3), data = house_data)
# summary(lm.regressionSplines)
# plot(lm.regressionSplines)
```

\pagebreak

# Generalised Additiv Models

```{r}
# library(splines)
# lm.regressionSplines <- lm(price ~ bs(living_area, df = 3), data = house_data)
# summary(lm.regressionSplines)
# plot(lm.regressionSplines)
```

\pagebreak

# Generalised linear models

```{r}

```

\pagebreak

# Tree's

```{r}
# library(ISLR)
# library(tree)
# 
# wine_tree <-  tree(price ~ . ,data = house_data)
# 
# summary(wine_tree)
# 
# plot(wine_tree)
# text(wine_tree, all=TRUE, cex=.8)

```

\pagebreak

# Support vector machines

```{r eval=FALSE, include=FALSE}

# #To Do separation still not working right 
# house_data <- house_data %>% filter(object_type_name ==  "Einfamilienhaus"  | object_type_name ==  "Wohnung")
# house_data <- house_data %>%  droplevels()
# house_data$object_type_name %>%  unique()
# 
# ## 75% of the sample size
# smp_size <- floor(0.75 * nrow(house_data))
# 
# ## set the seed to make your partition reproducible
# set.seed(1)
# train_ind <- sample(seq_len(nrow(house_data)), size = smp_size)
# house_train <- house_data[train_ind, ]
# house_test <- house_data[-train_ind, ]
# 
# 
# ggplot(house_data, aes(x=living_area, y=log(price))) + geom_point()
# 
# 
# number_of_observations <- 2000
# cost_range <- c(0.000005, 0.005,0.1,1,10,100,1000,10000)
# svm.models <- tune(
#   svm,
#   object_type_name ~ price + living_area + num_rooms,
#   data = house_train %>% top_n(number_of_observations),
#   kernel = "linear",
#   ranges = list(cost = cost_range),
#   scale = TRUE)
# svm.models <- svm.models$best.model
# summary(svm.models)
# 
# 
# plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price ~ living_area)
# plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price ~ num_rooms)
# table(predict = predict(svm.models, house_train),truth = house_train$object_type_name)
# 
# 
# number_of_observations <- 2000
# cost_range <- c(0.000005, 0.005,0.1,1,10,100,1000,10000)
# svm.models <- tune(
#   svm,
#   object_type_name ~ price + living_area + num_rooms,
#   data = house_train %>% top_n(number_of_observations),
#   kernel = "sigmoid",
#   ranges = list(cost = cost_range),
#   scale = TRUE)
# svm.models <- svm.models$best.model
# summary(svm.models)
# 
# 
# plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price ~ living_area)
# plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price ~ num_rooms)
# table(predict = predict(svm.models, house_train),truth = house_train$object_type_name)
# 
# 
# 
# number_of_observations <- 2000
# cost_range <- c(0.000005, 0.005,0.1,1,10,100,1000,10000)
# svm.models <- tune(
#   svm,
#   object_type_name ~ price + living_area + num_rooms,
#   data = house_train %>% top_n(number_of_observations),
#   kernel = "radial",
#   ranges = list(cost = cost_range),
#   scale = TRUE)
# svm.models <- svm.models$best.model
# summary(svm.models)
# 
# 
# plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price ~ living_area)
# plot(x = svm.models, data = house_train %>% top_n(number_of_observations), formula = price ~ num_rooms)
# table(predict = predict(svm.models, house_train),truth = house_train$object_type_name)
```

\pagebreak
